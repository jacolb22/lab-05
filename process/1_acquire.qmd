---
title: "Lab 05: Harvesting research data"
author: "Logan Jacobs"
date: 2024-02-28
date-modified: today
format:
  html:
    toc: true
    toc_depth: 2
bibliography: ["../bibliography.bib", "../packages.bib"]
---

# Data description

The data I am downloading is the Switchboard Dialog Act Corpus. This Corpus is a set of conversations 

The data is in an archived file on the [LDC](https://catalog.ldc.upenn.edu/LDC97S62).

In this case, I am going to download, unarchive and save the contents of the corpus to the `data/original/swda` directory.

The format of the file, according to the README file is a list of annotated phone conversations, organized by 42 tags. The files themselves are .utt files, and are contained in a group of folders, which altogether constitutes the original unarchived .tar.gz file

The license of the file is denoted as "LDC User Agreement for Non-Members". Upon reading this file, the license generally describes that the database can be used for non-commercial linguistic education, research, and technology development, allowing me to use it for my purposes.

# Data collection

Below describes my data collection process for the data described above.

Before anything else, I will install the necessary packages. Here I am installing `dplyr` @dplyr for piping more efficiently and `fs` @fs for the file system, as well as tools @tools, and tibble, @tibble, which I will need later for file extension viewing and the tibble data structure, respectively.

```{r}
#| label: setup-packages
#| message: false

# Load packages
library(dplyr) #for piping
library(fs) #file system
library(tools) #for file extension viewing
library(tibble) #for tibble data structure

```

The first step in the process is to try out using `download.file()` to acquire the archived file.

After this process, the file will be at `../data/original/swda.tar.gz`. Since it is a gzipped tarball file, I will have to unarchive it using `untar()` from base R.

```{r}
#| label: download-archive-test

# set url to file address
url <- "https://catalog.ldc.upenn.edu/docs/LDC97S62/swb1_dialogact_annot.tar.gz"
data_dest <- "../data/original/swda.tar.gz"

#creates temporary filespace for .tar.gz file
temp_file <- tempfile()

#downloads the file from the url to the data_dest
if (!dir.exists(data_dest)){
  download.file(url,temp_file)
  
  #unarchives the file, and copies it into the appropriate file directory
  untar(temp_file, exdir="../data/original/swda")
}

```

Upon completion of this process, the data will be in the appropriate directory: `../data/original/swda`.

To describe this data, it will be useful for it to be in a tibble format. The following code transforms the data into this tibble format.

<!-- How can I do this?

go through every file
get lines below header
add them to a string vector, perhaps add another two vectors for file number and line number
make that a tibble

when I tried this, it took 5 minutes before I stopped it.

-->

```{r}
# Set the path to the main folder containing subfolders with text documents
main_folder <- "../data/original/swda/"

# Get a list of all files in the main folder and its subfolders
all_files <- list.files(path = main_folder, recursive = TRUE, full.names = TRUE)
all_text = character(0) #creates empty chr vector, to be added to, looked up how to do this

# Iterate over each file
for(file in all_files) {
  # Check if the file is a utt document using file_ext (looked up function to do this)
  if(file_ext(file) == "utt") {
    # Read the content of the text document
    text <- readLines(file)
    text <- text[34:length(text)]
    text <- text[nzchar(text)] #removes empty rows (looked up way to do this)
    
    text <- gsub("^\\S*\\s{2,}","",text)
    text <- trimws(text, whitespace = "[\\s/]*") #didn't work with regular expressions for some reason, works now
    all_text <- c(all_text,text)
    
  }
}

speaker_vector <- substr(all_text,1,1) #looked up how to do this
all_text <- substr(all_text,3,nchar(all_text))
sentence_vector <- as.integer(substr(all_text,1,1))
all_text <- substr(all_text,6,nchar(all_text))
utterance_vector <- as.integer(substr(all_text,1,1))
all_text <- substr(all_text,4,nchar(all_text))

acquired_data_tbl <- tibble(
  Speaker_id = speaker_vector,
  Sentence_id = sentence_vector,
  Utterance_id = utterance_vector,
  Utterance = all_text 
)

print(acquired_data_tbl)

#LETS GOOOO IT ACTUALLY WORKS IM THE SMARTEST PERSON ALIVE


```


Now the data is organized in a tibble, with each of the rows containing the data that used to be semi-structured in a structured format.

